{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dimension_reduction_via_scikit-learn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqLnfWLOyh07",
        "colab_type": "text"
      },
      "source": [
        "# Compressing data via Dimension Reduction\n",
        "This page explores using  **Principal Component Analysis** (PCA) in scikit-learn for dimension reduction.\n",
        "\n",
        "Sources:\n",
        "\n",
        "* Python Machine Learning by Sebastian Raschka & Vahid Mirjalili\n",
        " -- Chapter 5 (PCA vis scikit-learn)\n",
        "*https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch05/ch05.ipynb\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "absTnNvj28w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import scipy.io\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v6FEHMcwXUm",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset (Julie's dataset)\n",
        "it's best to save the file 'CORRECT-PROBABILITIES.csv' locally then upload in colab with: \n",
        "\n",
        "->files->upload->path to 'CORRECT-PROBABILITIES.csv' \n",
        "\n",
        "You can find the file in drive/data_sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QIjwm_T3Ufz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('CORRECT-PROBABILITIES.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ce__ySz3ay0",
        "colab_type": "text"
      },
      "source": [
        "## Selecting input / output\n",
        "Since the majority of the non-zero probabilities are output in col 20, that's the one I use. Again, the goal here is to reduce dimensions, and to understand the tools available in Sci Kit Learn for doing so. We can more accurately reconfigure the data later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4yjijLtzFv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Select the number of features and which output col\n",
        "X = df.iloc[:, 1:5].values\n",
        "y = df.iloc[:, 20].values\n",
        "y = y.astype('int')\n",
        "\n",
        "# Split the training / test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.33, \n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmzye_5m9vCv",
        "colab_type": "text"
      },
      "source": [
        "## Import standard scalar to ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SoQKpgS9CV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Fit AND transform the train set\n",
        "X_train_std = sc.fit_transform(X_train, y_train)\n",
        "\n",
        "# ONLY transform the test set\n",
        "X_test_std = sc.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LsStVSN9lTS",
        "colab_type": "text"
      },
      "source": [
        "## Now we can use PCA (Principal Component Analysis)\n",
        "\n",
        "Documentation link(s): \n",
        "* https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "*https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpyOLvu19JWb",
        "colab_type": "code",
        "outputId": "03e7a3cb-f9cd-4ffb-f256-557023811652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "X_train_pca = pca.fit_transform(X_train_std)\n",
        "\n",
        "# Output the variance ration between the features\n",
        "pca.explained_variance_ratio_\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3667326 , 0.25335367, 0.24870434, 0.13120939])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaCV0P5CVPjl",
        "colab_type": "text"
      },
      "source": [
        "### Fit and train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB5eiFxy-oGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit a training set for pca\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_std)\n",
        "X_test_pca = pca.transform(X_test_std)\n",
        "\n",
        "# Train the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=0, solver='lbfgs')\n",
        "lr = lr.fit(X_train_pca, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8In62hN09SHN",
        "colab_type": "text"
      },
      "source": [
        "### Output some things to see what's going on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LasG-N9S9Qtm",
        "colab_type": "code",
        "outputId": "6f0f21d8-7f4b-47ee-e600-472dfd81c21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('X_train_std.shape: ', X_train_std.shape)\n",
        "print('X_train_pca.shape: ', X_train_pca.shape)\n",
        "print('X_train_std.size: ', X_train_std.size)\n",
        "\n",
        "# Features / dimensions should now be reduced according to n_components \n",
        "# specificed in PCA(n_components) (line[22])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_std.shape:  (18029, 4)\n",
            "X_train_pca.shape:  (18029, 2)\n",
            "X_train_std.size:  72116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9b2qufW4bWf",
        "colab_type": "text"
      },
      "source": [
        "### By now we've reducing the features / dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyqqxriO5gN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rv4tiEE_BK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}